{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP90ZUtQGaoZUncPLElVEDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chipzm/NUIG_Thesis/blob/main/Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installing the super-gradients package to get the YOLO NAS trainers and dataloaders\n",
        "!pip install super-gradients"
      ],
      "metadata": {
        "id": "OwGloaTHE2oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q split-folders"
      ],
      "metadata": {
        "id": "9yGvepi9E0vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drvlm0jW8Qkt"
      },
      "outputs": [],
      "source": [
        "# improting the required libraries\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import cv2\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import splitfolders\n",
        "\n",
        "from pycocotools.coco import COCO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to set the encoding\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "ZZgQ2I9K8gq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 - YOLO NAS (num classes: 1, epochs: 20)\n",
        "### Leopard Dataset"
      ],
      "metadata": {
        "id": "DZXKCcSa9NIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to get the list of available datasets under \"wild me\" foundation form the public storage of LILA BC\n",
        "!gsutil ls gs://public-datasets-lila/wild-me/"
      ],
      "metadata": {
        "id": "z5XC05kQ8h3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copying the leopard dataset tar.gz file into the local directory of colab\n",
        "!gsutil -m cp -r gs://public-datasets-lila/wild-me/leopard.coco.tar.gz ."
      ],
      "metadata": {
        "id": "3ZDEnB1I8iT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tar.gz files\n",
        "!tar -xzvf \"/content/leopard.coco.tar.gz\" -C \"/content/\""
      ],
      "metadata": {
        "id": "XFEUoqwx8jEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the COCO .json file\n",
        "data_source = COCO(annotation_file='/content/leopard.coco/annotations/instances_train2022.json')"
      ],
      "metadata": {
        "id": "RGnzUKlh9KsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the classes and the resective class_ids and creating dictionaries\n",
        "img_ids = data_source.getImgIds()\n",
        "catIds = data_source.getCatIds()\n",
        "\n",
        "categories = data_source.loadCats(catIds)\n",
        "categories.sort(key=lambda x: x['id'])\n",
        "\n",
        "classes = {}\n",
        "coco_labels = {}\n",
        "coco_labels_inverse = {}\n",
        "\n",
        "for c in categories:\n",
        "    coco_labels[len(classes)] = c['id']\n",
        "    coco_labels_inverse[c['id']] = len(classes)\n",
        "    classes[c['name']] = len(classes)\n",
        "\n",
        "class_num = {}"
      ],
      "metadata": {
        "id": "oR4tibMz9KwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making new directories to insert the changes json file and the respective images\n",
        "!mkdir -p dataset/labels dataset/images\n",
        "\n",
        "save_base_path  = 'dataset/labels/'\n",
        "save_image_path = 'dataset/images/'\n",
        "\n",
        "# remapping label id to 0~1\n",
        "label_transfer = {0: 0}"
      ],
      "metadata": {
        "id": "8UvpFL6k9K0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The json file is converted into txt files. The image_ids in the json file is used to determine which annotation is for which image. Once getting that information, the bounding box coordinates is obtained and\n",
        "the format gets converted to the required format for YOLO NAS.\n",
        "Seperate text files are generated and both the images and the these generated text files are then stored in the new folder \"images\" and \"labels\" respectively.\n",
        "'''\n",
        "for index, img_id in tqdm.tqdm(enumerate(img_ids), desc='change .json file to .txt file'):\n",
        "    img_info = data_source.loadImgs(img_id)[0]\n",
        "\n",
        "    # Change the path containing the folder to the file name\n",
        "    save_name = img_info['file_name'].replace('/', '_')\n",
        "\n",
        "    # Removing file extensions\n",
        "    file_name = save_name.split('.')[0]\n",
        "\n",
        "    # Get the width and height of each image\n",
        "    height = img_info['height']\n",
        "    width = img_info['width']\n",
        "\n",
        "    # Save the converted txt file into tmp folder created\n",
        "    save_path = save_base_path + file_name + '.txt'\n",
        "    is_exist = False # To check whether the file already exists\n",
        "\n",
        "    with open(save_path, mode='w') as fp:\n",
        "      annotation_id = data_source.getAnnIds(img_id)\n",
        "      boxes = np.zeros((0, 5))\n",
        "      if len(annotation_id) == 0: # if there are no annotations for that image or no classes in the image\n",
        "            fp.write('')\n",
        "            continue\n",
        "\n",
        "      annotations = data_source.loadAnns(annotation_id)\n",
        "      lines = ''\n",
        "\n",
        "      for annotation in annotations:\n",
        "        # to get the label of the object\n",
        "        label = coco_labels_inverse[annotation['category_id']]\n",
        "\n",
        "        if label in label_transfer.keys():\n",
        "          is_exist = True\n",
        "          box = annotation['bbox']\n",
        "          if box[2] < 1 or box[3] < 1:\n",
        "            continue\n",
        "          box[0] = round((box[0] + box[2] / 2) / width, 6)\n",
        "          box[1] = round((box[1] + box[3] / 2) / height, 6)\n",
        "          box[2] = round(box[2] / width, 6)\n",
        "          box[3] = round(box[3] / height, 6)\n",
        "\n",
        "          if label not in class_num.keys():\n",
        "            class_num[label] = 0\n",
        "\n",
        "          class_num[label] += 1\n",
        "          lines = lines + str(label)\n",
        "\n",
        "          for i in box:\n",
        "            lines += ' ' + str(i)\n",
        "          lines += '\\n'\n",
        "\n",
        "      fp.writelines(lines)\n",
        "\n",
        "    if is_exist:\n",
        "        # if there is a target type directory, copy it\n",
        "      shutil.copy('/content/leopard.coco/images/train2022/{}'.format(img_info['file_name']), os.path.join(save_image_path, save_name))\n",
        "    else:\n",
        "      os.remove(save_path)"
      ],
      "metadata": {
        "id": "zY6iD6Az9K4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the total number of files in the images and labels folders\n",
        "img_src = []\n",
        "ann_src = []\n",
        "\n",
        "img = r'/content/dataset/images'\n",
        "ann = r'/content/dataset/labels'\n",
        "\n",
        "for root, dirs, files in os.walk(img):\n",
        "  for filename in files:\n",
        "    img_src.append(filename)\n",
        "\n",
        "for root, dirs, files in os.walk(ann):\n",
        "  for filename in files:\n",
        "    ann_src.append(filename)\n",
        "\n",
        "len(img_src), len(ann_src), len(img_src)+len(ann_src)"
      ],
      "metadata": {
        "id": "h3mP4KC79K78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to remove a directory and its sub directories\n",
        "directory = ['/content/leopard.coco']\n",
        "\n",
        "for dir in directory:\n",
        "  shutil.rmtree(dir)"
      ],
      "metadata": {
        "id": "XS6Au4Uc9K_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to split the dataset into train, test and validation dataset of the ratio 80%, 10% and 10%\n",
        "import splitfolders\n",
        "splitfolders.ratio('dataset', output=\"leopard_dataset\", seed=1337, ratio=(.8, 0.1,0.1))"
      ],
      "metadata": {
        "id": "9kPvkR9h9LD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the total number of files in the train folder\n",
        "train_img = []\n",
        "train_ann = []\n",
        "\n",
        "img = r'/content/leopard_dataset/train/images'\n",
        "ann = r'/content/leopard_dataset/train/labels'\n",
        "\n",
        "for root, dirs, files in os.walk(img):\n",
        "  for filename in files:\n",
        "    train_img.append(filename)\n",
        "\n",
        "for root, dirs, files in os.walk(ann):\n",
        "  for filename in files:\n",
        "    train_ann.append(filename)\n",
        "\n",
        "len(train_img), len(train_ann), len(train_img)+len(train_ann)"
      ],
      "metadata": {
        "id": "Cewf2SE-9LHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the total number of files in the test folder\n",
        "test_img = []\n",
        "test_ann = []\n",
        "\n",
        "img = r'/content/leopard_dataset/test/images'\n",
        "ann = r'/content/leopard_dataset/test/labels'\n",
        "\n",
        "for root, dirs, files in os.walk(img):\n",
        "  for filename in files:\n",
        "    test_img.append(filename)\n",
        "\n",
        "for root, dirs, files in os.walk(ann):\n",
        "  for filename in files:\n",
        "    test_ann.append(filename)\n",
        "\n",
        "len(test_img), len(test_ann), len(test_img)+len(test_ann)"
      ],
      "metadata": {
        "id": "nT3RG6o49LK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the total number of files in the val folder\n",
        "val_img = []\n",
        "val_ann = []\n",
        "\n",
        "img = r'/content/leopard_dataset/val/images'\n",
        "ann = r'/content/leopard_dataset/val/labels'\n",
        "\n",
        "for root, dirs, files in os.walk(img):\n",
        "  for filename in files:\n",
        "    val_img.append(filename)\n",
        "\n",
        "for root, dirs, files in os.walk(ann):\n",
        "  for filename in files:\n",
        "    val_ann.append(filename)\n",
        "\n",
        "len(val_img), len(val_ann), len(val_img)+len(val_ann)"
      ],
      "metadata": {
        "id": "5kPmnBwR9LPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries and packages\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "import random\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from super_gradients.training import Trainer, dataloaders, models\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val\n",
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback"
      ],
      "metadata": {
        "id": "6I9bc_E3-96X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a class o store the required trainer, dataset, dataloader and model parameters\n",
        "class config:\n",
        "  #trainer params\n",
        "  exp_name = 'leopard_id' #assigning a new experiment name\n",
        "  chkpt = 'checkpoint' #assigning a new checkpoint name which stores all the log files and weights during the training\n",
        "\n",
        "  #dataset params\n",
        "  data_dir = '/content/leopard_dataset'\n",
        "\n",
        "  train_images = 'train/images'\n",
        "  train_labels = 'train/labels'\n",
        "\n",
        "  val_images = 'val/images'\n",
        "  val_labels = 'val/labels'\n",
        "\n",
        "  test_images = 'test/images'\n",
        "  test_labels = 'test/labels'\n",
        "\n",
        "  classes = ['leopard'] #name of the classes availabe in the dataset.\n",
        "  num_classes = len(classes)\n",
        "\n",
        "  #dataloader params - you can add whatever PyTorch dataloader params you have could be different across train, val, and test\n",
        "  dataloader_params = {'batch_size':8, 'num_workers':2}\n",
        "\n",
        "  #model params\n",
        "  model_name = 'yolo_nas_l' #the model of yolo nas used. This is a large model\n",
        "  pretrained_weights = 'coco' #pre trained coco weights are used"
      ],
      "metadata": {
        "id": "fbYF0IH--995"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiating the trainer\n",
        "trainer = Trainer(experiment_name = config.exp_name, ckpt_root_dir = config.chkpt)"
      ],
      "metadata": {
        "id": "sWeHpx-F--N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning to dataloaders and datasets\n",
        "train_data = coco_detection_yolo_format_train(dataset_params = {'data_dir': config.data_dir,\n",
        "                                'images_dir': config.train_images,\n",
        "                                'labels_dir': config.train_labels,\n",
        "                                'classes': config.classes},\n",
        "              dataloader_params = config.dataloader_params)\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(dataset_params = {'data_dir': config.data_dir,\n",
        "                                'images_dir': config.val_images,\n",
        "                                'labels_dir': config.val_labels,\n",
        "                                'classes': config.classes},\n",
        "              dataloader_params = config.dataloader_params)\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(dataset_params = {'data_dir': config.data_dir,\n",
        "                                'images_dir': config.test_images,\n",
        "                                'labels_dir': config.test_labels,\n",
        "                                'classes': config.classes},\n",
        "              dataloader_params = config.dataloader_params)"
      ],
      "metadata": {
        "id": "l5LJzi-q--SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to plot some training images\n",
        "train_data.dataset.plot()"
      ],
      "metadata": {
        "id": "E6ENPp53--WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating the model\n",
        "model = models.get(config.model_name,\n",
        "                   num_classes=config.num_classes,\n",
        "                   pretrained_weights=config.pretrained_weights)"
      ],
      "metadata": {
        "id": "BvOn2f_G--aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining training metrics and parameters\n",
        "train_params = {# ENABLING SILENT MODE\n",
        "    \"average_best_models\":True,\n",
        "    \"warmup_mode\": \"linear_epoch_step\",\n",
        "    \"warmup_initial_lr\": 1e-5,\n",
        "    \"lr_warmup_epochs\": 5,\n",
        "    \"initial_lr\": 3e-4,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 0.1,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
        "    \"max_epochs\": 20, #assigning 20 epochs for this run\n",
        "    \"mixed_precision\": True,\n",
        "    \"loss\": PPYoloELoss(\n",
        "        use_static_assigner=False,\n",
        "        num_classes=config.num_classes,\n",
        "        reg_max=16\n",
        "    ),\n",
        "    \"valid_metrics_list\": [\n",
        "        DetectionMetrics_050(\n",
        "            score_thres=0.1,\n",
        "            top_k_predictions=300,\n",
        "            num_cls=config.num_classes,\n",
        "            normalize_targets=True,\n",
        "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
        "                score_threshold=0.01,\n",
        "                nms_top_k=1000,\n",
        "                max_predictions=300,\n",
        "                nms_threshold=0.7\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        "    \"metric_to_watch\": 'mAP@0.50'\n",
        "}"
      ],
      "metadata": {
        "id": "83PuY_s5--dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "trainer.train(model = model,\n",
        "              training_params = train_params,\n",
        "              train_loader = train_data,\n",
        "              valid_loader = val_data)"
      ],
      "metadata": {
        "id": "UystW2cS--g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze training metrics using tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {config.chkpt}/{config.exp_name}"
      ],
      "metadata": {
        "id": "MFwgrJtC--kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to copy the entore dorectory to gdrive\n",
        "%cp -av \"/content/checkpoint\" \"/content/drive/MyDrive\"\n",
        "\n",
        "#to zip the checkpoint directory to download or copy\n",
        "!zip -r /content/leopard_chekpt.zip /content/checkpoint"
      ],
      "metadata": {
        "id": "bPrK48ug--oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#geting the best model of the run from the chkpt path\n",
        "best_model = models.get(config.model_name,\n",
        "                        num_classes = config.num_classes,\n",
        "                        checkpoint_path = os.path.join(config.chkpt, config.exp_name, 'average_model.pth'))"
      ],
      "metadata": {
        "id": "yJ6U2DcWA91h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the best model on testing dataset\n",
        "trainer.test(model = best_model,\n",
        "             test_loader = test_data,\n",
        "             test_metrics_list = DetectionMetrics_050(score_thres=0.1,\n",
        "                                                   top_k_predictions=300,\n",
        "                                                   num_cls=config.num_classes,\n",
        "                                                   normalize_targets=True,\n",
        "                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01,\n",
        "                                                                                                          nms_top_k=1000,\n",
        "                                                                                                          max_predictions=300,\n",
        "                                                                                                          nms_threshold=0.7)\n",
        "                                                   )\n",
        "             )"
      ],
      "metadata": {
        "id": "q20KOxhQA95r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to analyse and inference the testing data on the best model"
      ],
      "metadata": {
        "id": "1HFemS_DA99t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference with trained model\n",
        "import supervision as sv\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path = '/content/leopard_dataset/test/images',\n",
        "    annotations_directory_path = '/content/leopard_dataset/test/labels',\n",
        "    data_yaml_path='/content/leopard.yaml\",\n",
        "    force_masks = False\n",
        ")\n",
        "\n",
        "CONFIDENCE_TRESHOLD = 0.5\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for image_name, image in ds.images.items():\n",
        "    result = list(best_model.predict(image, conf=CONFIDENCE_TRESHOLD))[0]\n",
        "    detections = sv.Detections(xyxy = result.prediction.bboxes_xyxy,\n",
        "                               confidence=result.prediction.confidence,\n",
        "                               class_id=result.prediction.labels.astype(int)\n",
        "                               )\n",
        "    predictions[image_name] = detections"
      ],
      "metadata": {
        "id": "EcGcaplPA-Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize inference results\n",
        "random.seed(10)\n",
        "\n",
        "MAX_IMAGE_COUNT = 5\n",
        "\n",
        "n = min(MAX_IMAGE_COUNT, len(ds.images))\n",
        "\n",
        "keys = list(ds.images.keys())\n",
        "keys = random.sample(keys, n)\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "images = []\n",
        "titles = []\n",
        "\n",
        "for key in keys:\n",
        "    frame_with_annotations = box_annotator.annotate(\n",
        "        scene=ds.images[key].copy(),\n",
        "        detections=ds.annotations[key],\n",
        "        skip_label=True\n",
        "    )\n",
        "    images.append(frame_with_annotations)\n",
        "    titles.append('annotations')\n",
        "    frame_with_predictions = box_annotator.annotate(\n",
        "        scene=ds.images[key].copy(),\n",
        "        detections=predictions[key],\n",
        "        skip_label=True\n",
        "    )\n",
        "    images.append(frame_with_predictions)\n",
        "    titles.append('predictions')\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_images_grid(images=images, titles=titles, grid_size=(n, 2), size=(2 * 4, n * 4))"
      ],
      "metadata": {
        "id": "TfdSXAerA-KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "!pip install -q onemetric\n",
        "\n",
        "from onemetric.cv.object_detection import ConfusionMatrix\n",
        "\n",
        "keys = list(ds.images.keys())\n",
        "\n",
        "annotation_batches, prediction_batches = [], []\n",
        "\n",
        "for key in keys:\n",
        "    annotation=ds.annotations[key]\n",
        "    annotation_batch = np.column_stack((\n",
        "        annotation.xyxy,\n",
        "        annotation.class_id\n",
        "    ))\n",
        "    annotation_batches.append(annotation_batch)\n",
        "\n",
        "    prediction=predictions[key]\n",
        "    prediction_batch = np.column_stack((\n",
        "        prediction.xyxy,\n",
        "        prediction.class_id,\n",
        "        prediction.confidence\n",
        "    ))\n",
        "    prediction_batches.append(prediction_batch)\n",
        "\n",
        "confusion_matrix = ConfusionMatrix.from_detections(\n",
        "    true_batches=annotation_batches,\n",
        "    detection_batches=prediction_batches,\n",
        "    num_classes=len(ds.classes),\n",
        "    conf_threshold=CONFIDENCE_TRESHOLD\n",
        ")\n",
        "\n",
        "confusion_matrix.plot(os.path.join(HOME, \"confusion_matrix.png\"), class_names=ds.classes)"
      ],
      "metadata": {
        "id": "B3R2AI_7A-Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting with new data after 20 epochs\n",
        "url = 'https://cdn.britannica.com/40/146340-050-297B2798/Leopard-tree-Kenya-Masai-Mara-National-Reserve.jpg'\n",
        "best_model.predict(url).show()"
      ],
      "metadata": {
        "id": "B2YtK4TKA-Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing the counter into the images to determine how many of each species is available in the image\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import Counter\n",
        "\n",
        "# pred = best_model.predict('https://img.theweek.in/content/dam/week/news/india/images/2020/12/22/leopard-pti.jpg')\n",
        "pred = best_model.predict('https://cdn.britannica.com/40/146340-050-297B2798/Leopard-tree-Kenya-Masai-Mara-National-Reserve.jpg')\n",
        "# pred = best_model.predict('https://i.pinimg.com/1200x/da/8f/72/da8f729a05ad064830f30cc757d2d277.jpg')\n",
        "# pred = best_model.predict('https://media.istockphoto.com/id/1314203068/photo/leopard.jpg?s=2048x2048&w=is&k=20&c=zHRm1lyeITCZBP02sFaGvqoF0D8w1ngBVYrs6R9oR_c=')\n",
        "\n",
        "result = list(pred)[0]\n",
        "\n",
        "class_names = list(result.class_names)\n",
        "\n",
        "counter = Counter(list(result.prediction.labels.astype(\"int\")))\n",
        "output = list(counter.items())\n",
        "output = list(map(lambda x: (class_names[x[0]],x[1]),output))\n",
        "\n",
        "# saving the predicted image\n",
        "pred.save(output_folder=\"/content/output\")\n",
        "\n",
        "print(output) # To get the number of objects in each class\n",
        "\n",
        "\n",
        "# path\n",
        "path = r'/content/output/pred_0.jpg'\n",
        "\n",
        "# Reading an image in default mode\n",
        "image = cv2.imread(path)\n",
        "\n",
        "for i in range(len(output)):\n",
        "  org = (50, 50*i+50) #assigning the position in the image where the cout has to be displayed\n",
        "  image = cv2.putText(image, str(output[i][0]) + ': '+ str(output[i][1]), org, cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255), thickness =2, lineType = cv2.LINE_AA)\n",
        "\n",
        "# Displaying the image with the count\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "rNn85RpuA-Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Y5TCCM5A-aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2 - YOLO NAS (num classes: 81, epochs: 25)\n",
        "## Kaggle Dataset and LILA BC Hyena Dataset"
      ],
      "metadata": {
        "id": "nrucclbWA-e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the kaggle data\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d antoreepjana/animals-detection-images-dataset\n",
        "\n",
        "!unzip /content/animals-detection-images-dataset.zip"
      ],
      "metadata": {
        "id": "h-njzn2rDLMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=\"/content\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "test_dir = os.path.join(data_dir, \"test\")\n",
        "\n",
        "all_train_subdir=glob.glob(train_dir+\"/*\")\n",
        "all_test_subdir=glob.glob(test_dir+\"/*\")\n",
        "\n",
        "train_classes=[os.path.basename(path) for path in all_train_subdir]\n",
        "test_classes=[os.path.basename(path) for path in all_test_subdir]\n",
        "\n",
        "print(\"There is %d classes in train dataset, and %d classes in test dataset\"%(len(train_classes), len(test_classes)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuJdCW74DL2E",
        "outputId": "a1540f90-fa97-4172-cfc9-17ef1f998cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 80 classes in train dataset, and 80 classes in test dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the hyena dataset from the LILA BC public folder\n",
        "!gsutil -m cp -r gs://public-datasets-lila/wild-me/hyena.coco.tar.gz ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QGFIFjjA-ix",
        "outputId": "d61c9cc4-f59e-4aa5-a165-71be7a4d5d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://public-datasets-lila/wild-me/hyena.coco.tar.gz...\n",
            "/ [0/1 files][    0.0 B/  3.2 GiB]   0% Done                                    \r==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "- [1/1 files][  3.2 GiB/  3.2 GiB] 100% Done  37.4 MiB/s ETA 00:00:00           \n",
            "Operation completed over 1 objects/3.2 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tar.gz files\n",
        "!tar -xzvf \"/content/hyena.coco.tar.gz\" -C \"/content/\""
      ],
      "metadata": {
        "id": "DdgXBeGhA-m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/hyena.coco/annotations/instances_train2022.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpYE8RXEA-rG",
        "outputId": "7b758b90-1a12-4f35-8d34-f74eb1bc2131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['info', 'licenses', 'categories', 'images', 'annotations', 'parts'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "for item in data['categories']:\n",
        "  item['id'] = 80\n",
        "\n",
        "for item1 in data['annotations']:\n",
        "  item1['category_id'] = 80\n",
        "\n",
        "with open(file_path, 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(data, json_file)"
      ],
      "metadata": {
        "id": "EvUU5yZ5A-vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/hyena.coco/annotations/instances_train2022.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "data['categories']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFO45aRJ8qmQ",
        "outputId": "a2638f0c-77a9-4f25-f05e-b0ca8378ba94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 80, 'name': 'hyena', 'supercategory': 'animal'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the json file and converting the class_id to 80 to match\n",
        "data_source = COCO(annotation_file='/content/hyena.coco/annotations/instances_train2022.json')\n",
        "\n",
        "img_ids = data_source.getImgIds()\n",
        "catIds = data_source.getCatIds()\n",
        "\n",
        "categories = data_source.loadCats(catIds)\n",
        "categories.sort(key=lambda x: x['id'])\n",
        "\n",
        "classes = {}\n",
        "coco_labels = {}\n",
        "coco_labels_inverse = {}\n",
        "\n",
        "for c in categories:\n",
        "  print(c)\n",
        "  coco_labels[80] = c['id']\n",
        "  coco_labels_inverse[c['id']] = 80\n",
        "  classes[c['name']] = 80\n",
        "\n",
        "class_num = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAHeAEzv57cd",
        "outputId": "685dd0ea-0961-4a33-908f-99e8160b7fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "{'id': 80, 'name': 'hyena', 'supercategory': 'animal'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes, coco_labels, coco_labels_inverse, class_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVhaMUn-57hS",
        "outputId": "cf179f4a-e758-4638-8fef-f553eabde63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'hyena': 80}, {80: 80}, {80: 80}, {})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p dataset/labels dataset/images\n",
        "\n",
        "save_base_path  = 'dataset/labels/'\n",
        "save_image_path = 'dataset/images/'\n",
        "\n",
        "# remapping label id to 0~1\n",
        "label_transfer = {80:80}"
      ],
      "metadata": {
        "id": "SHCC12CA57lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#writing the annotations to txt files according to the image names\n",
        "for index, img_id in tqdm.tqdm(enumerate(img_ids), desc='change .json file to .txt file'):\n",
        "    img_info = data_source.loadImgs(img_id)[0]\n",
        "\n",
        "    # Change the path containing the folder to the file name\n",
        "    save_name = img_info['file_name'].replace('/', '_')\n",
        "\n",
        "    # Removing file extensions\n",
        "    file_name = save_name.split('.')[0]\n",
        "\n",
        "    # Get the width and height of each image\n",
        "    height = img_info['height']\n",
        "    width = img_info['width']\n",
        "\n",
        "    # Save the converted txt file into tmp folder created\n",
        "    save_path = save_base_path + file_name + '.txt'\n",
        "    is_exist = False # To check whether the file already exists\n",
        "\n",
        "    # print(save_path)\n",
        "    with open(save_path, mode='w') as fp:\n",
        "      annotation_id = data_source.getAnnIds(img_id)\n",
        "      boxes = np.zeros((0, 5))\n",
        "      if len(annotation_id) == 0: # if there are no annotations for that image or no classes in the image\n",
        "            fp.write('')\n",
        "            continue\n",
        "\n",
        "      annotations = data_source.loadAnns(annotation_id)\n",
        "      lines = ''\n",
        "\n",
        "      for annotation in annotations:\n",
        "        # to get the label of the object\n",
        "        label = coco_labels_inverse[annotation['category_id']]\n",
        "\n",
        "        if label in label_transfer.keys():\n",
        "          is_exist = True\n",
        "          box = annotation['bbox']\n",
        "          if box[2] < 1 or box[3] < 1:\n",
        "            continue\n",
        "          box[0] = round((box[0] + box[2] / 2) / width, 6)\n",
        "          box[1] = round((box[1] + box[3] / 2) / height, 6)\n",
        "          box[2] = round(box[2] / width, 6)\n",
        "          box[3] = round(box[3] / height, 6)\n",
        "\n",
        "          if label not in class_num.keys():\n",
        "            class_num[label] = 0\n",
        "\n",
        "          class_num[label] += 1\n",
        "          lines = lines + str(label)\n",
        "\n",
        "          for i in box:\n",
        "            lines += ' ' + str(i)\n",
        "          lines += '\\n'\n",
        "\n",
        "      fp.writelines(lines)\n",
        "\n",
        "    if is_exist:\n",
        "        # if there is a target type directory, copy it\n",
        "      shutil.copy('/content/hyena.coco/images/train2022/{}'.format(img_info['file_name']), os.path.join(save_image_path, save_name))\n",
        "    else:\n",
        "      os.remove(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4UA6fdd57pG",
        "outputId": "0ff45c91-62b0-46ed-dcb1-8b579b7ac96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "change .json file to .txt file: 3104it [00:43, 71.39it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p copy_dataset/images copy_dataset/labels\n",
        "\n",
        "#adding the prefix 'Hyena_ to the image names and label names and copying them into a new folder\n",
        "img_src = r'/content/dataset/images'\n",
        "labels_src = r'/content/dataset/labels'\n",
        "\n",
        "img_tgt = '/content/copy_dataset/images'\n",
        "labels_tgt = '/content/copy_dataset/labels'\n",
        "\n",
        "new_pre = 'Hyena_'\n",
        "\n",
        "for filename in os.listdir(img_src):\n",
        "  if filename.endswith('.jpg'):\n",
        "    # print(filename)\n",
        "    os.rename(os.path.join(img_src, filename), os.path.join(img_tgt, ''.join([new_pre, filename])))\n",
        "\n",
        "\n",
        "for filename in os.listdir(labels_src):\n",
        "  if filename.endswith('.txt'):\n",
        "    # print(filename)\n",
        "    os.rename(os.path.join(labels_src, filename), os.path.join(labels_tgt, ''.join([new_pre, filename])))"
      ],
      "metadata": {
        "id": "qYqzp6YJB3Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to remove a directory and its sub directories\n",
        "directory = ['/content/hyena_dataset']\n",
        "\n",
        "for dir in directory:\n",
        "  shutil.rmtree(dir)"
      ],
      "metadata": {
        "id": "YtWrB4KBB3BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the files into test and train since the Kaggle dataset has this forlder format\n",
        "splitfolders.ratio('/content/copy_dataset', output=\"hyena_dataset\", seed=1337, ratio=(.8, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKk67rbVB29c",
        "outputId": "e175a7bf-52fc-4515-c921-7f381dda6447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 0 files [00:00, ? files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgyG3atWB20W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBIshTC2B2fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d08mU3IA57ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNAFEe7V57xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tuZkkoT5716"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rd5qKGBL576C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FYwcIakj57-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZ-WYkT158CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdSu4IoL58FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VW9NsdKE58JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qijhQxzt58M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99LMtARu58Qe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}